{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YncEbyIYRi2G"
      },
      "source": [
        "In the following demonstration, we see a basic example of how to **Use a Vector Store as an Index** using **chromadb** to split a document into chunks, embed it using an open-source embedding model, load it into Chroma, and then query it.\n",
        "\n",
        "\n",
        "data source used with this example: https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
        "\n",
        "LlamaIndex also supports different vector stores as the storage backend for VectorStoreIndex. [Full list](https://docs.llamaindex.ai/en/stable/community/integrations/vector_stores/#vector-store-examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra2LNBHuRi2I"
      },
      "source": [
        "#### Steps to create a Chroma Index:\n",
        "1. Install and import LlamaIndex (+other dependencies)\n",
        "2. Setup OpenAI\n",
        "3. Create a Chroma new client and collection\n",
        "4. Define Embed function\n",
        "5. Load Documents\n",
        "6. Set up ChromaVectorStore and load in data\n",
        "7. Query Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grpr1BJDRi2I"
      },
      "source": [
        "Step 1: Install LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "Kw5GAvi1Ri2J"
      },
      "outputs": [],
      "source": [
        "pip install llama-index-vector-stores-chroma\n",
        "pip install llama-index-embeddings-huggingface\n",
        "pip install llama-index chromadb --quiet\n",
        "pip install chromadb\n",
        "pip install sentence-transformers\n",
        "pip install pydantic==1.10.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "owqPPggSRi2J"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "import chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFPVQnORi2K"
      },
      "source": [
        "Step 2: Setup OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "gIISpZIORi2K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHlcqbKqRi2K"
      },
      "source": [
        "Step 3: create client and a new collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVppx8S-Ri2L"
      },
      "outputs": [],
      "source": [
        "chroma_client = chromadb.EphemeralClient()\n",
        "chroma_collection = chroma_client.create_collection(\"quickstart\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGE7rj38Ri2L"
      },
      "source": [
        "Step 4: define embedding function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VLaEsg0Ri2L"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Jv1t4LHRi2L"
      },
      "source": [
        "Step 5: load documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRecNVyIRi2L"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"./docs/\").load_data()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bECm9QrgRi2M"
      },
      "source": [
        "Step 6: set up ChromaVectorStore and load in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-A8NREiRi2M"
      },
      "outputs": [],
      "source": [
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qKlcsCjRi2M"
      },
      "source": [
        "Step7: Query Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6UJ3bdSRi2M"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What did the author do growing up?\")\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}